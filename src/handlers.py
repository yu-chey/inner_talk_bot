import asyncio
import logging
from datetime import datetime, timezone
from aiogram.exceptions import TelegramBadRequest
from aiogram import Router, F
from aiogram.filters import Command, StateFilter
from aiogram.fsm.context import FSMContext
from . import config
from . import keyboards
from . import photos
from . import texts
from . import states
from google.genai import types
from aiogram.types import Message
from aiogram.enums import ParseMode

logger = logging.getLogger(__name__)

router = Router()

async def _save_user_profile_async(collection, user_id, username, first_name):
    """Ð¤Ð¾Ð½Ð¾Ð²Ð¾Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¸Ð»Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð² MongoDB."""
    try:
        await collection.update_one(
            {"user_id": user_id, "type": "user_profile"},
            {"$set": {
                "username": username,
                "first_name": first_name,
                "last_active": datetime.now(timezone.utc)
            }},
            upsert=True
        )
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ/Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: {e}")

async def _save_to_db_async(collection, data):
    """Ð¤Ð¾Ð½Ð¾Ð²Ð¾Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² MongoDB."""
    try:
        await collection.insert_one(data)
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² MongoDB Ð² Ñ„Ð¾Ð½Ð¾Ð²Ð¾Ð¼ Ñ€ÐµÐ¶Ð¸Ð¼Ðµ: {e}")


@router.message(Command("start"))
async def start_handler(message: Message, state: FSMContext, users_collection) -> None:
    await state.set_state(states.SessionStates.idle)

    user = message.from_user
    asyncio.create_task(_save_user_profile_async(
        users_collection,
        user.id,
        user.username,
        user.first_name
    ))

    caption_text = texts.MAIN_MENU_CAPTION
    await message.answer_photo(
        photo=photos.main_photo,
        caption=caption_text,
        reply_markup=keyboards.main_menu,
        parse_mode=ParseMode.MARKDOWN)


async def update_thinking_message(bot, chat_id: int, message_id: int, stop_event: asyncio.Event):
    animation_texts = [
        "**ðŸ” ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ** Ð²Ð°Ñˆ Ð´Ð¸Ð°Ð»Ð¾Ð³...",
        "**ðŸ§  Ð¡Ð¸Ð½Ñ‚ÐµÐ·Ð¸Ñ€ÑƒÑŽ** Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ...",
        "**ðŸ’¬ Ð¤Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÑŽ** Ð¾Ñ‚Ð²ÐµÑ‚...",
        "**âš™ï¸ Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÑŽ** Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐ¾Ð²ÐµÑ‚..."
    ]
    delay = 1.0

    try:
        while not stop_event.is_set():
            for text_frame in animation_texts:
                if stop_event.is_set():
                    break

                try:
                    await bot.edit_message_text(
                        chat_id=chat_id,
                        message_id=message_id,
                        text=text_frame,
                        parse_mode=ParseMode.MARKDOWN
                    )
                except TelegramBadRequest as e:
                    if "message is not modified" not in str(e):
                        return

                await asyncio.sleep(delay)

    except asyncio.CancelledError:
        pass
    except Exception as e:
        logger.error(f"Error in update_thinking_message: {e}")

@router.message(F.content_type != "text", StateFilter(states.SessionStates.in_session))
async def non_text_in_session_handler(message: Message) -> None:
    await message.answer(
        "ðŸš« **ÐžÑˆÐ¸Ð±ÐºÐ°:** Ð¯ â€” Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð˜Ð˜-Ð¿ÑÐ¸Ñ…Ð¾Ð»Ð¾Ð³ Ð¸ Ð¼Ð¾Ð³Ñƒ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ **Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ**.",
        parse_mode=ParseMode.MARKDOWN
    )

@router.message(StateFilter(states.SessionStates.in_session))
async def echo_handler(message: Message, state: FSMContext, generate_content_sync_func, users_collection, bot,
                       gemini_client, count_tokens_sync_func) -> None:
    user_text = message.text
    user_id = message.from_user.id
    chat_id = message.chat.id
    username = message.from_user.username

    if not user_text:
        await message.answer("ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ.")
        return

    current_data = await state.get_data()
    ai_style = current_data.get("ai_style", "default")
    real_user_message_count = current_data.get("real_user_message_count", 0) + 1

    is_miracle_asked = current_data.get('miracle_question_asked', False)
    is_scaling_asked = current_data.get('scaling_question_asked', False)

    if real_user_message_count == 2 and not is_miracle_asked:
        logger.info(f"User {user_id} reached 2 messages. Initiating Miracle Question.")
        await state.update_data(initiate_miracle_question=True, miracle_question_asked=True)

    elif real_user_message_count == 5 and not is_miracle_asked and not is_scaling_asked:
        logger.info(f"User {user_id} reached 5 messages. Initiating Scaling Question.")
        await state.update_data(initiate_scaling_question=True, scaling_question_asked=True)

    else:
        if current_data.get('initiate_miracle_question'):
            await state.update_data(initiate_miracle_question=False)
        if current_data.get('initiate_scaling_question'):
            await state.update_data(initiate_scaling_question=False)

    style_modifier = ""
    if ai_style == "empathy":
        style_modifier = (
            "Ð¢Ð’ÐžÐ™ ÐŸÐ Ð˜ÐžÐ Ð˜Ð¢Ð•Ð¢: Ð¡ÐµÐ¹Ñ‡Ð°Ñ Ñ‚Ñ‹ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ ÑÐ¼Ð¿Ð°Ñ‚Ð¸Ñ‡Ð½Ñ‹Ð¼ Ð¸ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÑŽÑ‰Ð¸Ð¼. "
            "Ð¤Ð¾ÐºÑƒÑÐ¸Ñ€ÑƒÐ¹ÑÑ Ð½Ð° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ñ‡ÑƒÐ²ÑÑ‚Ð² Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ, Ð¿Ð¾ÐºÐ°Ð¶Ð¸, Ñ‡Ñ‚Ð¾ Ñ‚Ñ‹ ÑÐ»Ñ‹ÑˆÐ¸ÑˆÑŒ ÐµÐ³Ð¾ Ð±Ð¾Ð»ÑŒ. "
            "Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ñ€ÑÐ¼Ñ‹Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð², ÑƒÐ²ÐµÐ»Ð¸Ñ‡ÑŒ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ„Ñ€Ð°Ð· ÑÐ¾Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ."
        )
    elif ai_style == "action":
        style_modifier = (
            "Ð¢Ð’ÐžÐ™ ÐŸÐ Ð˜ÐžÐ Ð˜Ð¢Ð•Ð¢: Ð¢Ñ‹ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ñ‹Ð¼ Ð¸ Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼ Ð½Ð° Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ. "
            "Ð˜Ð·Ð±ÐµÐ³Ð°Ð¹ Ð»Ð¸ÑˆÐ½Ð¸Ñ… Ñ„Ñ€Ð°Ð· ÑÐ¾Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ. Ð¡Ñ€Ð°Ð·Ñƒ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°Ð¹ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ ÑˆÐ°Ð³Ð¸, Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐ¹ Ð·Ð°Ð´Ð°Ñ‡Ð¸ "
            "Ð¸ Ñ„Ð¾ÐºÑƒÑÐ¸Ñ€ÑƒÐ¹ÑÑ Ð½Ð° Ð¿Ð»Ð°Ð½Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹. Ð’ Ð²Ñ‹Ð²Ð¾Ð´Ð°Ñ… '3-2-1' Ð´ÐµÐ»Ð°Ð¹ ÑƒÐ¿Ð¾Ñ€ Ð½Ð° '1ï¸âƒ£ Ð”ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ'."
        )

    history = current_data.get("current_dialog", [])
    last_ai_message_id = current_data.get('last_ai_message_id')

    if last_ai_message_id:
        try:
            await bot.edit_message_reply_markup(
                chat_id=chat_id,
                message_id=last_ai_message_id,
                reply_markup=None
            )
        except TelegramBadRequest:
            pass

    is_summary_present = (
            len(history) > 0 and
            history[0].get('content', '').startswith("ÐŸÐ Ð•Ð”Ð«Ð”Ð£Ð©Ð˜Ð™ ÐšÐžÐÐ¡ÐŸÐ•ÐšÐ¢ Ð¡Ð•Ð¡Ð¡Ð˜Ð˜:")
    )
    summary_content_dict = history[0] if is_summary_present else None

    dialog_messages_only = history[1:] if is_summary_present else history.copy()

    user_message_content_dict = {"role": "user", "content": user_text}
    dialog_messages_only.append(user_message_content_dict)

    updated_data = await state.get_data()

    miracle_prompt_modifier = ""
    if updated_data.get('initiate_miracle_question'):
        miracle_prompt_modifier = "FSMContext ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ ÐºÐ»ÑŽÑ‡ 'initiate_miracle_question'. ÐÐµÐ¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸ Ð£ÐŸÐ ÐÐ–ÐÐ•ÐÐ˜Ð•: Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð¾ Ð§ÑƒÐ´Ðµ, ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð¿Ð¾ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ 5."

    scaling_prompt_modifier = ""
    if updated_data.get('initiate_scaling_question'):
        scaling_prompt_modifier = "FSMContext ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ ÐºÐ»ÑŽÑ‡ 'initiate_scaling_question'. ÐÐµÐ¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸ Ð£ÐŸÐ ÐÐ–ÐÐ•ÐÐ˜Ð•: Ð¨ÐºÐ°Ð»Ð° ÐšÐ¾Ð¼Ð¿ÐµÑ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚Ð¸, ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð¿Ð¾ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ 6."

    full_modifier = f"{style_modifier}\n\n{miracle_prompt_modifier}\n\n{scaling_prompt_modifier}"

    base_prompt_with_style = f"{config.SYSTEM_PROMPT_TEXT}\n\n{full_modifier}"

    if is_summary_present and summary_content_dict:
        final_system_prompt = f"{summary_content_dict['content']}\n\n{base_prompt_with_style}"
        logger.info("ÐšÐ¾Ð½ÑÐ¿ÐµÐºÑ‚ Ð¸ ÐÐºÑ†ÐµÐ½Ñ‚ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ñ‹ Ð² ÑÐ¸ÑÑ‚ÐµÐ¼Ð½ÑƒÑŽ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸ÑŽ Ð´Ð»Ñ Gemini.")
    else:
        final_system_prompt = base_prompt_with_style
        logger.info(f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ ÐÐºÑ†ÐµÐ½Ñ‚: {ai_style}")

    new_contents_gemini = [
        types.Content(
            role=item['role'],
            parts=[types.Part(text=item['content'])]
        )
        for item in dialog_messages_only
    ]

    loop = asyncio.get_event_loop()
    total_token_count = 0

    try:
        token_response = await loop.run_in_executor(
            None,
            count_tokens_sync_func,
            gemini_client,
            'gemini-2.5-flash',
            new_contents_gemini,
        )
        total_token_count = token_response.total_tokens
    except Exception as e:
        logger.error(f"Error counting tokens: {e}")
        pass

    if total_token_count >= config.MAX_TOKENS_PER_SESSION:
        await message.answer(
            f"ðŸ•°ï¸ **Ð›Ð¸Ð¼Ð¸Ñ‚ ÑÐµÑÑÐ¸Ð¸:** ÐžÐ±Ñ‰Ð¸Ð¹ Ð¾Ð±ÑŠÐµÐ¼ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° ({total_token_count} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²) "
            f"Ð´Ð¾ÑÑ‚Ð¸Ð³ Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼Ð° (~{config.MAX_TOKENS_PER_SESSION} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²). \n"
            f"Ð”Ð»Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ ÐºÐ¾Ð½ÑÐ¿ÐµÐºÑ‚Ð°, Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ **'Ð—Ð°ÐºÐ¾Ð½Ñ‡Ð¸Ñ‚ÑŒ ÑÐµÑÑÐ¸ÑŽ'**.",
            reply_markup=keyboards.end_session_menu,
            parse_mode=ParseMode.MARKDOWN
        )
        return

    thinking_message = await message.answer("...")

    stop_event = asyncio.Event()
    animation_task = asyncio.create_task(
        update_thinking_message(
            bot,
            chat_id,
            thinking_message.message_id,
            stop_event
        )
    )

    ai_response = "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð¿Ñ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð½Ð° ÑÑ‚Ð¾Ñ€Ð¾Ð½Ðµ Ð˜Ð˜. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð·Ð°ÐºÐ¾Ð½Ñ‡Ð¸Ñ‚ÑŒ ÑÐµÑÑÐ¸ÑŽ Ð¸ Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ Ð½Ð¾Ð²ÑƒÑŽ."

    try:
        ai_response_obj = await loop.run_in_executor(
            None,
            generate_content_sync_func,
            gemini_client,
            'gemini-2.5-flash',
            new_contents_gemini,
            final_system_prompt
        )
        ai_response = ai_response_obj.text
    except Exception as e:
        logger.error(f"Gemini API call error: {e}")

    stop_event.set()

    try:
        await animation_task
    except asyncio.CancelledError:
        pass

    final_message = thinking_message

    try:
        await thinking_message.edit_text(
            text=ai_response,
            reply_markup=keyboards.end_session_menu,
            parse_mode=ParseMode.MARKDOWN
        )
    except TelegramBadRequest as e:
        logger.warning(f"Failed to edit thinking message: {e}")
        final_message = await message.answer(
            ai_response,
            reply_markup=keyboards.end_session_menu,
            parse_mode=ParseMode.MARKDOWN
        )

    current_time = datetime.now(timezone.utc)

    asyncio.create_task(_save_to_db_async(users_collection, {
        "user_id": user_id,
        "type": "user_message",
        "text": user_text,
        "timestamp": current_time,
        "username": username,
    }))

    asyncio.create_task(_save_to_db_async(users_collection, {
        "user_id": user_id,
        "type": "model_response",
        "text": ai_response,
        "timestamp": current_time,
    }))

    dialog_messages_only.append({"role": "model", "content": ai_response})

    history_to_save = dialog_messages_only

    if is_summary_present and summary_content_dict:
        history_to_save.insert(0, summary_content_dict)
        logger.info("ÐšÐ¾Ð½ÑÐ¿ÐµÐºÑ‚ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰ÐµÐ½ Ð² Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ FSMContext (Ð¸Ð½Ð´ÐµÐºÑ 0).")

    real_user_message_count = current_data.get("real_user_message_count", 0) + 1

    await state.update_data(
        current_dialog=history_to_save,
        last_ai_message_id=final_message.message_id,
        real_user_message_count=real_user_message_count
    )

@router.message(F.content_type != "text")
async def non_text_idle_handler(message: Message) -> None:
    print(message.photo[-1].file_id)